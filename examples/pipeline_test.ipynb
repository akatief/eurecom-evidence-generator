{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Pipeline test ###\n",
    "\n",
    "In this notebook we will try a possible textual claim generation to be implemented later as part of the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra import initialize,compose\n",
    "from src.evidence import FeverousRandomRetriever\n",
    "from src.pipeline import ClaimGeneratorPipeline\n",
    "from src.claim import FeverousGenerator\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "initialize(config_path='../src/config/', job_name=\"test_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/t5_4.bin'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [29]\u001B[0m, in \u001B[0;36m<cell line: 11>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m rng \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mdefault_rng(cfg\u001B[38;5;241m.\u001B[39mseed)\n\u001B[0;32m      3\u001B[0m retriever \u001B[38;5;241m=\u001B[39m FeverousRandomRetriever(cfg\u001B[38;5;241m.\u001B[39mdata_path_notebook,\n\u001B[0;32m      4\u001B[0m                                          cfg\u001B[38;5;241m.\u001B[39mnum_evidence,\n\u001B[0;32m      5\u001B[0m                                          cfg\u001B[38;5;241m.\u001B[39mn_pieces,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      9\u001B[0m                                          cfg\u001B[38;5;241m.\u001B[39mseed\n\u001B[0;32m     10\u001B[0m                                          )\n\u001B[1;32m---> 11\u001B[0m generator \u001B[38;5;241m=\u001B[39m \u001B[43mFeverousGenerator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m ClaimGeneratorPipeline([retriever,generator])\n\u001B[0;32m     14\u001B[0m output,text_evidence \u001B[38;5;241m=\u001B[39m pipeline\u001B[38;5;241m.\u001B[39mgenerate(\u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;66;03m# Right now, FeverousRetriever doesn't support an input table\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\eurecom-evidence-generator\\src\\claim\\feverous_generator.py:12\u001B[0m, in \u001B[0;36mFeverousGenerator.__init__\u001B[1;34m(self, model_path)\u001B[0m\n\u001B[0;32m     10\u001B[0m config \u001B[38;5;241m=\u001B[39m ppb\u001B[38;5;241m.\u001B[39mAutoConfig\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt5-small\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m ppb\u001B[38;5;241m.\u001B[39mT5ForConditionalGeneration(config)\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32mc:\\users\\simop\\documents\\github\\eurecom-evidence-generator\\venv\\lib\\site-packages\\torch\\serialization.py:699\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[0;32m    696\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    697\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 699\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[0;32m    701\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[0;32m    702\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[0;32m    703\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[0;32m    704\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[1;32mc:\\users\\simop\\documents\\github\\eurecom-evidence-generator\\venv\\lib\\site-packages\\torch\\serialization.py:231\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    229\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 231\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    233\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32mc:\\users\\simop\\documents\\github\\eurecom-evidence-generator\\venv\\lib\\site-packages\\torch\\serialization.py:212\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    211\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 212\u001B[0m     \u001B[38;5;28msuper\u001B[39m(_open_file, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../models/t5_4.bin'"
     ]
    }
   ],
   "source": [
    "cfg = compose(config_name=\"config_pipeline\")\n",
    "rng = np.random.default_rng(cfg.seed)\n",
    "retriever = FeverousRandomRetriever(cfg.notebook.data_path,\n",
    "                                         cfg.num_evidence,\n",
    "                                         cfg.n_pieces,\n",
    "                                         cfg.table_per_page,\n",
    "                                         cfg.evidence_per_table,\n",
    "                                         cfg.column_per_table,\n",
    "                                         cfg.seed\n",
    "                                         )\n",
    "generator = FeverousGenerator(cfg.model_path)\n",
    "\n",
    "pipeline = ClaimGeneratorPipeline([retriever,generator])\n",
    "output,text_evidence = pipeline.generate(None) # Right now, FeverousRetriever doesn't support an input table\n",
    "\n",
    "#output, text_evidence = generator.generate(output)\n",
    "\n",
    "for i,(o,e) in enumerate(zip(output,text_evidence)):\n",
    "    print(f'Claim {i}: ')\n",
    "    print('Generated: ', o)\n",
    "    print('Evidence : ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}